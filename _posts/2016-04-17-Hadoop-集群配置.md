---
layout: post
title: Hadoop2.7.2 集群配置
subtitle: 亲自动手配置hadoop集群
author: carm
header-img: img/home-bg.jpg
categories: 大数据
tag:
  - hadoop
---
# Apache Hadoop

### 了解Hadoop
[Apache Hadoop](https://en.wikipedia.org/wiki/Apache_Hadoop)是一个开源分布式框架，可以运行在由成千上万个普通机器的节点构成的集群上，通过分布式存储和计算模型来处理大数据集。

### Hadoop优点
* 存储容量大
* 高容错性
* 高可靠性
* 高扩展性
* 分布式存储

### Hadoop不足
* 不适合低延迟数据访问
* 不能处理流式数据
* 不能对文件进行修改

### 包括以下部分(Hadoop2.7.2)
* Hadoop Common ：为其他Hadoop模块提供底层支持何常用工具类库及API编程接口
* [HDFS](https://en.wikipedia.org/wiki/Apache_Hadoop#HDFS)：负责数据的存储、管理和容错，是Hadoop系统的基础层
* [YARN](http://baike.baidu.com/link?url=x7hLkwyYxqxXEpJCuq1dYOBzjIz2b_3EJeFeOZj-yKaUmF-l3PKaBOqm-MGBplP3Nc-5PmRc3NLrveD9Ep6YWK)：通用资源管理系统，为上层提供统一的资源管理与调度
* [MapReduce](https://en.wikipedia.org/wiki/Apache_Hadoop#JobTracker_and_TaskTracker:_the_MapReduce_engine)：是一种编程模型，用于大规模数据集（大于1TB）的并行运算

### HDFS Daemon
HDFS将节点分为两类：NameNode和DataNode。NameNode存储集群元数据，DataNode存储真正的数据

* NameNode
* SecondNameNode
* DataNode

### YARN Daemon
* ResourceManager
* NodeManager
* WebAppProxy

RM控制整个集群并管理应用程序及基础计算资源分配。NM提供针对集群中每个节点的服务，监视容器的执行和资源使用，跟踪节点健康。

### MapReduce
*  Job History Server

## Hadoop 集群配置

#### 1、集群环境
<table style="color:green;">
<thead>
<tr><th>操作系统</th> <th>主机地址</th> <th>主机名</th> <th>用户</th></tr>
</thead>
<tbody>
<tr><td>ubuntu-15.10</td> <td>168.168.2.223</td> <td>master</td> <td>hadoop</td></tr>
<tr><td>centos7.2</td> <td>168.168.2.222</td> <td>slave1</td> <td>hadoop</td></tr>
<tr><td>centos7.2</td> <td>168.168.2.221</td> <td>slave2</td> <td>hadoop</td></tr>
</tbody>
</table>

##### 修改主机名可以使用下面方法：
	$ sudo hostnamectl set-hostname 主机名
或者,直接修改/etc/hostname 文件

	$ sudo vi /etc/hostname

##### 添加用户组(hadoop)与用户(hadoop)
	$ groupadd hadoop
	$ useradd -m -g hadoop -s /bin/bash hadoop

#### 2、修改上面三台机器的/etc/hosts文件，添加如下内容：
	168.168.2.223  master
	168.168.2.222  slave1
	168.168.2.221  slave2
这样可以通过使用主机名来互相访问，并且在接下来的配置文件中使用主机名代替IP地址可以更加灵活控制集群

##### 配置SSH,使master主机可以无需输入密码访问slave1和slave2主机
可以参考我的另一篇文章[SSH免密码登录配置](http://blog.jecarm.com/linux/2016/04/10/ssh-conf/)

<p style="color:red">注：下面的配置以master主机为例，其他机器配置需和master机器配置一致</p>

#### 3、安装jdk1.8.0_77
Oracle官方下载：[jdk-8u77-linux-x64.tar.gz](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)

将jdk-8u77-linux-x64.tar.gz 移动到/usr/lib目录，解压缩。

	$ cd /usr/lib
	$ tar zxf jdk-8u77-linux-x64.tar.gz

解压缩完成后目录结构为：/usr/lib/jdk1.8.0_77

##### 设置java环境变量
打开/etc/profile文件`sudo vi /etc/profile`，添加如下内容：

	export JAVA_HOME=/usr/lib/jdk1.8.0_77
	export JRE_HOME=${JAVA_HOME}/jre
	export CLASSPATH=${JAVA_HOME}/lib:${JRE_HOME}/lib
	export PATH=${JAVA_HOME}/bin:$PATH
设置完成后运行`source /etc/profile`使配置生效

#### 4、安装Hadoop2.7.2
	$ cd /home/hadoop
	$ sudo wget http://apache.fayea.com/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz
	$ $ tar zxf /home/hadoop/hadoop-2.7.2.tar.gz

##### 配置环境变量
执行：`sudo vi /etc/profile `在文件末尾添加如下内容：

	export HADOOP_PREFIX=/home/hadoop/hadoop-2.7.2
	export HADOOP_CONF_DIR=/home/hadoop/hadoop-2.7.2/etc/hadoop
	export HADOOP_YARN_HOME=/home/hadoop/hadoop-2.7.2
	export PATH=$HADOOP_PREFIX/bin:$PATH

#### 5、配置Hadoop
官方文档参考：[Cluster Setup](http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/ClusterSetup.html)

#####  Hadoop-env.sh
	export JAVA_HOME=/usr/lib/jdk1.8.0_77
注：默认配置export JAVA_HOME=$JAVA_HOME，找不到java环境，故改成了绝对路径

##### core-site.xml 配置文档
	<configuration>
		    <property>
		        <name>fs.defaultFS</name>
		        <value>hdfs://master:9000</value>
		    </property>
		    <property>
		        <name>hadoop.tmp.dir</name>
		        <value>/home/hadoop/hdfs/tmp</value>
		         <description>A base for other temporary directories.</description>
		    </property>
			<property>
		        <name>io.file.buffer.size</name>
		        <value>131072</value>
		    <description>Size of read/write buffer used in SequenceFiles.</description>
		    </property>
	</configuration>

##### hdfs-site.xml
	<configuration>
	    <property>
	        <name>dfs.replication</name>
	        <value>2</value>
	    </property>
	    <property>
	        <name>dfs.namenode.name.dir</name>
	        <value>/home/hadoop/hdfs/name1,/home/hadoop/hdfs/name2</value>
	    </property>
	    <property>
	        <name>dfs.namenode.datanode.dir</name>
	        <value>/home/hadoop/hdfs/data</value>
	    </property>
	    <property>
	        <name>dfs.namenode.secondary.http-address</name>
	         <value>master:9001</value>
	    </property>
	    <property>
	        <name>dfs.blocksize</name>
	        <value>268435456</value>
	    </property>
	    <property>
	        <name>dfs.namenode.handler.count</name>
	        <value>100</value>
	    </property>
	</configuration>

##### yarn-site.xml
	<configuration>
	    <property>
	        <name>yarn.nodemanager.aux-services</name>
	        <value>mapreduce_shuffle</value>
	    </property>
	    <property>
	        <name>yarn.resourcemanager.address</name>
	        <value>master:8031</value>
	    </property>

	    <property>
	        <name>yarn.resourcemanager.scheduler.address</name>
	        <value>master:8032</value>
	    </property>
	    <property>
	        <name>yarn.resourcemanager.resource-tracker.address</name>
	        <value>master:8033</value>
	    </property>
	    <property>
	        <name>yarn.resourcemanager.admin.address</name>
	        <value>master:8034</value>
	    </property>
	    <property>
	        <name>yarn.resourcemanager.webapp.address</name>
	        <value>master:8088</value>
	    </property>
	    <property>
	        <name>yarn.resourcemanager.hostname</name>
	        <value>master</value>
	    </property>
	    <property>
	        <name>yarn.scheduler.minimum-allocation-mb</name>
	        <value>256</value>
	    </property>
	    <property>
	        <name>yarn.scheduler.maximum-allocation-mb</name>
	        <value>6144</value>
	    </property>
	    <property>
	        <name>yarn.nodemanager.resource.memory-mb</name>
	        <value>256</value>
	    </property>
	    <property>
	        <name>yarn.nodemanager.vmem-pmem-ratio</name>
	        <value>20</value>
	    </property>
	    <property>
        <name>yarn.nodemanager.local-dirs</name>
        <value>/home/hadoop/comma</value>
	    </property>
	    <property>
	        <name>yarn.nodemanager.log-dirs</name>
	        <value>/home/hadoop/log</value>
	    </property>
	    <property>
	        <name>yarn.nodemanager.log.retain-seconds</name>
	        <value>10800</value>
	    </property>
	    <property>
	        <name>yarn.nodemanager.remote-app-log-dir</name>
	        <value>/logs</value>
	    </property>
	    <property>
	        <name>yarn.nodemanager.remote-app-log-dir-suffix</name>
	        <value>logs</value>
	    </property>
	    <property>
	        <name>yarn.nodemanager.aux-services</name>
	        <value>mapreduce_shuffle</value>
	    </property>
	    <property>
	        <name>yarn.log-aggregation.retain-seconds</name>
	        <value>-1</value>
	    </property>
	    <property>
	        <name>yarn.log-aggregation.retain-check-interval-seconds</name>
	        <value>-1</value>
	    </property>
	</configuration>

##### mapred.site.xml
	<configuration>
        <property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
        </property>
        <property>
            <name>mapreduce.map.memory.mb</name>
            <value>1536</value>
        </property>
        <property>
            <name>mapreduce.map.java.opts</name>
            <value>-Xmx1024M</value>
        </property>
        <property>
            <name>mapreduce.reduce.memory.mb</name>
            <value>3072</value>
        </property>
        <property>
            <name>mapreduce.reduce.java.opts</name>
            <value>-Xmx2560M</value>
        </property>
        <property>
            <name>mapreduce.task.io.sort.mb</name>
            <value>512</value>
        </property>
        <property>
            <name>mapreduce.task.io.sort.factor</name>
            <value>100</value>
        </property>
        <property>
            <name>mapreduce.reduce.shuffle.parallelcopies</name>
            <value>50</value>
        </property>
        <property>
            <name>mapreduce.jobhistory.address</name>
            <value>master:10020</value>
        </property>
        <property>
            <name>mapreduce.jobhistory.webapp.address</name>
            <value>master:19888</value>
        </property>
        <property>
            <name>mapreduce.jobhistory.intermediate-done-dir</name>
            <value>/mr-history/tmp</value>
        </property>
        <property>
            <name>mapreduce.jobhistory.done-dir</name>
            <value>/mr-history/done</value>
        </property>
    </configuration>

##### slaves
	168.168.2.222
	168.168.2.221

##### 启动hadoop
在master主机上输入下面指令：

格式化hdfs文件系统

	$ $HADOOP_PREFIX/bin/hdfs namenode -format <cluster_name>
启动NomeNode,SecondaryNameNode,DataNode

	$ $HADOOP_PREFIX/sbin/start-dfs.sh
可以通过`jps`命令查看master和slaves主机上启动的java进程

启动yarn，使用下面命令：

	$ $HADOOP_PREFIX/sbin/start-yarn.sh
启动MapReduce

	$ $HADOOP_PREFIX/sbin/mr-jobhistory-daemon.sh --config $HADOOP_CONF_DIR start historyserver

##### 停止hadoop
	$ $HADOOP_PREFIX/sbin/mr-jobhistory-daemon.sh --config $HADOOP_CONF_DIR stop historyserver
	$ $HADOOP_PREFIX/sbin/stop-yarn.sh
	$ $HADOOP_PREFIX/sbin/stop-dfs.sh
或者

	$ $HADOOP_PREFIX/sbin/stop-all.sh

##### 通过浏览器查看管理
<table style="color:green;">
<thead>
<tr><th>Daemon</th> <th>访问链接</th> <th>默认端口</th> </tr>
</thead>
<tbody>
<tr><td>NameNode</td> <td>http://master:50070/</td> <td>50070</td> </tr>
<tr><td>ResourceManager</td> <td>http://master:8088/</td> <td>8088</td> </tr>
<tr><td>MapReduce JobHistory Server</td> <td>http://master:19888/</td> <td>19888</td> </tr>
</tbody>
</table>

#### 6、配置过程中一些问题
问题一：
 <p style="color:red;">INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)</p>

将core-site.xml配置文件

	<property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>

改为

	<property>
        <name>fs.defaultFS</name>
        <value>hdfs://master:9000</value>
    </property>

问题二：
<p style="color:red;">关于master主机与slaves机器中用户名的设置问题</p>

刚开始我这三台机器设置的用户名各不相同，分别为：carm(master)，hadoop（slave1）,ucarm（slave2）。在master主机上启动NomeNode没有问题，但启动不了远程slave1和slave2的DataNode节点。查看日志后发现，DataNode需要通过ssh服务连接启动，但是看了下发现ssh连接的两个远程地址分别为：carm@168.168.2.222和carm@168.168.2.221。问题来了，两个远程主机根本没有carm这个用户，所以不可能连接上,正确的连接应该是hadoop@168.168.2.222和ucarm@168。168.2.221。

原因是：Hadoop中启动远程DataNode是读取slaves文件中的主机地址，然后通过ssh连接到各主机，但ssh连接时默认使用了master主机的用户名（carm），所以导致了错误。故最后将所有的用户名改为hadoop。

问题三：
<p style="color:red;">java.net.NoRouteToHostException: 没有到主机的路由</p>

原因是Centos7.2忘了关闭防火墙,ubuntu-15.10默认防火墙是关闭的
查看防火墙状态，与关闭防火墙：

ubuntu-15.10:
	
	# 查看防火请状态
	$ sudo ufw status
	# 关闭防火墙
	$ sudo ufw disable
	
centos7.2:

	# 查看防火请状态
	$ sudo firewall-cmd --state
	# 关闭防火墙
	$ sudo systemctl stop firewalld.service
	# 禁止开机启动
	$ sudo systemctl disable firewalld.service
